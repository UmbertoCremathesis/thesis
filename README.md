# Offline Reinforcement Learning for Robotic Control â€” Bachelor's Thesis

This repository contains the code and experiments developed for my Bachelor's thesis in Computer Engineering at the University of Padova. The goal of the project is to explore and evaluate offline reinforcement learning algorithms in robotic simulation environments using datasets from the D4RL suite (accessed via Minari) and training with D3RLPY.

---

## âš™ï¸ Prerequisites

Before getting started, make sure you have:
- Conda (Anaconda or Miniconda)
- Python 3.10+
- Git

Check with:
```bash
conda --version
```

---

## ðŸ“ Repository Structure

```
thesis/
â”‚
â”œâ”€â”€ gifs/                             # rollout visualizations and videos
â”œâ”€â”€ Minari/                           # local helper code (ignored by Git)
â”œâ”€â”€ notebooks/                        # Jupyter Notebooks for each phase
â”‚   â”œâ”€â”€ 00_presentazione.ipynb        # initial dataset exploration (Pen)
â”‚   â”œâ”€â”€ 01_caricamento_datasets.ipynb # loading and inspecting Pen + Relocate datasets
â”‚   â””â”€â”€ 02_algoritmi_d3rlpy.ipynb     # IQL and other offline RL experiments
â”‚   â””â”€â”€ 03_due_dita.ipynb             # Pen task with only wrist, index, and thumb active 
â”‚
â”œâ”€â”€ results/                          # logs, plots, evaluation metrics
â”œâ”€â”€ scripts/                          # utility scripts (e.g., download datasets)
â”‚   â””â”€â”€ download_datasets.py
â”œâ”€â”€ environment.yml                   # conda environment definition
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ðŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/UmbertoCremathesis/thesis.git
cd thesis
```

### 2. Create and activate the environment

```bash
conda env create --file=environment.yml
conda activate thesis-env
```

### 3. Download required datasets

This project uses datasets from the D4RL suite via Minari. Run the following script **before using the notebooks**:

```bash
python scripts/download_datasets.py
```

This will download all necessary datasets (e.g., Pen, Door, Relocate, Hammer) used throughout the project.

> Make sure that the `thesis-env` environment is active when you run the script.

### 4. Register the environment as a Jupyter kernel (once)

```bash
python -m ipykernel install --user --name thesis-env --display-name "Python (thesis-env)"
```

### 5. Launch Jupyter Lab

```bash
jupyter lab
```

Then, switch the notebook kernel to `Python (thesis-env)`.

---

## ðŸ§ª Notebooks

| Notebook                         | Description |
|----------------------------------|-------------|
| `00_presentazione.ipynb`         | Initial exploration of Adroit Pen dataset |
| `01_caricamento_datasets.ipynb` | Loads and analyzes Pen and Relocate datasets via Minari |
| `02_algoritmi_d3rlpy.ipynb`     | Trains offline RL policies (e.g., IQL) using D3RLPY |
| `03_due_dita.ipynb`             | Pen task with only wrist, index, and thumb active |

---

## ðŸ“¦ Environment

Key packages used:

- `minari`, `d3rlpy`, `gymnasium`, `mujoco`, `robosuite`
- `torch`, `wandb`, `pybullet`, `moviepy`, `pygame`
- `jupyterlab`, `numpy`, `pandas`, `matplotlib`

Full details in [`environment.yml`](./environment.yml)

---

## ðŸ‘¤ Author

**Umberto Crema**  
Bachelor's Degree in Computer Engineering  
University of Padova â€” Academic Year 2024/2025