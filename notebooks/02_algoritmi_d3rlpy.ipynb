{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92017d89-0c42-440d-90a0-12a2b97c51b7",
   "metadata": {},
   "source": [
    "# Introduzione\n",
    "\n",
    "Obiettivo di questo notebook: testare il training degli algoritmi Implicit Q-Learning, Conservative Q-Learning, Behavior Cloning, TD3 con Behavior Cloning sull dataset `D4RL/pen/expert-v2`.\n",
    "\n",
    "Il task \"pen\" richiede a una mano robotica (Adroit Hand) di manipolare una penna per portarla in una certa posizione nello spazio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550e8a2-780f-467d-a4fe-32f3133d807f",
   "metadata": {},
   "source": [
    "# Caricamento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ddc05d-f16b-45bd-bf5a-75acd3370550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minari\n",
    "import time\n",
    "import numpy as np\n",
    "from d3rlpy.algos import IQLConfig, CQLConfig, BCConfig, TD3PlusBCConfig, BCQConfig, AWACConfig\n",
    "from d3rlpy.datasets import MDPDataset\n",
    "from d3rlpy.constants import ActionSpace\n",
    "from d3rlpy.metrics import EnvironmentEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fcffad0-33f7-4cc2-8cf4-5b302434725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = minari.load_dataset(\"D4RL/hammer/expert-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27c7a549-fa6d-4f18-9e92-b1a36b4bae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodi totali: 5000\n",
      "Spazio osservazioni: Box(-inf, inf, (46,), float64)\n",
      "Spazio azioni: Box(-1.0, 1.0, (26,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Episodi totali:\", dataset.total_episodes)\n",
    "print(\"Spazio osservazioni:\", dataset.observation_space)\n",
    "print(\"Spazio azioni:\", dataset.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4abfdaa-7b5b-4935-8e6a-9f34c84b31f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EpisodeData(id=0, total_steps=200, observations=ndarray of shape (201, 46) and dtype float64, actions=ndarray of shape (200, 26) and dtype float32, rewards=ndarray of 200 floats, terminations=ndarray of 200 bools, truncations=ndarray of 200 bools, infos=dict with the following keys: ['success'])\n"
     ]
    }
   ],
   "source": [
    "episode = next(dataset.iterate_episodes())\n",
    "print(episode)\n",
    "\n",
    "#print(f\"Osservazioni: \\n{episode.observations[0]}\")\n",
    "#print(f\"Actions: \\n{episode.actions[0]}\")\n",
    "#print(f\"Rewards: \\n{episode.rewards[0]}\")\n",
    "#print(f\"Terminations: \\n{episode.terminations[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972fc83-ff5e-4832-b653-4b1eb1d50710",
   "metadata": {},
   "source": [
    "The task to be completed consists on repositioning the blue pen to match the orientation of the green target. The base of the hand is fixed. The target is also randomized to cover all configurations. The task will be considered successful when the orientations match within tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e55371-306a-4a54-bcf9-8adb06914207",
   "metadata": {},
   "source": [
    "# Preparazione dataset\n",
    "\n",
    "d3rlpy si aspetta che il dataset sia composto da transizioni, in cui ogni elemento contiene uno stato, un’azione, una ricompensa, lo stato successivo e un flag terminale, tutti allineati in modo che lo stato e l’azione alla posizione i corrispondano alla transizione verso lo stato alla posizione i+1. A tal fine, la libreria mette a disposizione la classe MDPDataset, che consente di creare facilmente un oggetto dataset nel formato richiesto. All'interno del dataset non c'è la distinzione in episodi, tutti gli step sono uniti in un unico array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d238d2-572c-4f73-858b-90aa9f9f5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499206, 45)\n",
      "(499206, 24)\n",
      "(499206,)\n",
      "(499206,)\n",
      "\u001b[2m2025-04-29 11:48.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(24,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float64')], shape=[(45,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float64')], shape=[(1,)])\u001b[0m\n",
      "\u001b[2m2025-04-29 11:48.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m24\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "observations = []\n",
    "actions = []\n",
    "rewards = []\n",
    "terminals = []\n",
    "\n",
    "for episode in dataset.iterate_episodes():\n",
    "    # si rimuove l'ultimo elemento, in quanto non ha una successiva azione associata\n",
    "    obs = episode.observations[:-1]\n",
    "    actions_ep = episode.actions\n",
    "    rewards_ep = episode.rewards\n",
    "    dones = np.array(episode.terminations) | np.array(episode.truncations)\n",
    "\n",
    "    observations.append(obs)\n",
    "    actions.append(actions_ep)\n",
    "    rewards.append(rewards_ep)\n",
    "    terminals.append(dones)\n",
    "\n",
    "# ora observations è un array di 4958 array (episodi) di 100 array circa (step) di array (osservazioni). stesso discorso per gli altri\n",
    "\n",
    "# si uniscono gli array in modo da avere, per ogni step del dataset osservazioni, azione, reward, terminali\n",
    "observations = np.concatenate(observations)\n",
    "actions = np.concatenate(actions)\n",
    "rewards = np.concatenate(rewards)\n",
    "terminals = np.concatenate(terminals)\n",
    "\n",
    "# ora observations è un array di 499206 (step in tutto il dataset) di array (osservazioni) . stesso discorso per gli altri\n",
    "print(observations.shape)\n",
    "print(actions.shape)\n",
    "print(rewards.shape)\n",
    "print(terminals.shape)\n",
    "\n",
    "d3_dataset = MDPDataset(observations, actions, rewards, terminals, action_space = ActionSpace.CONTINUOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b3639-9799-4972-8a25-8fcf792fd28b",
   "metadata": {},
   "source": [
    "# Implicit Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d5d7e-4176-4c4d-aa0a-696f13de7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "iql = IQLConfig().create(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f3214-7536-4fae-9d87-db0175af77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iql.build_with_dataset(d3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab968c-37cb-4722-855f-e807f6f5a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment()\n",
    "\n",
    "iql.fit(\n",
    "    dataset=d3_dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\"env\": EnvironmentEvaluator(env)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7658b-d8a8-4f3a-aa68-2b663ff6d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment(render_mode=\"human\", camera_id=2)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = iql.predict(obs[None])[0]\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(f\"Reward totale: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177cc9cc-b1a4-40d4-8e79-521645029329",
   "metadata": {},
   "source": [
    "# Conservative Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc421d7-29f6-4082-96c0-3df6757b11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cql = CQLConfig().create(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec3c23-fe3e-4eb6-b31d-5cff65d7b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cql.build_with_dataset(d3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f8b94-fb51-4fe2-91ac-d12a93dd86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment()\n",
    "\n",
    "cql.fit(\n",
    "    dataset=d3_dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\"env\": EnvironmentEvaluator(env)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e3051-2a19-47a5-b50d-2f7189f2f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment(render_mode=\"human\", camera_id=2)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = cql.predict(obs[None])[0]\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(f\"Reward totale: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91064eee-7ae1-4aad-9934-a4253828d3f0",
   "metadata": {},
   "source": [
    "# Behavior Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc95ac5-5837-4c0a-b55d-879e86c0d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BCConfig().create(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3baef-09b5-4cc3-8ca8-e73fefeee3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.build_with_dataset(d3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb6184-b8b6-4b4f-a808-e1e51a32752a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = dataset.recover_environment()\n",
    "\n",
    "bc.fit(\n",
    "    dataset=d3_dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\"env\": EnvironmentEvaluator(env)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa0afc-7a8c-48c0-9198-9779a788ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment(render_mode=\"human\", camera_id=2)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = bc.predict(obs[None])[0]\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(f\"Reward totale: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4d6c5-327c-4fd7-bdd7-a35870e89f1d",
   "metadata": {},
   "source": [
    "# TD3 + BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b24d6-73a9-43a3-bec5-b959f4fd332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "td3bc = TD3PlusBCConfig().create(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79744949-f12f-4a87-9f80-2fa45f2dd8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "td3bc.build_with_dataset(d3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073b650-ca61-46be-b7d3-412e1755f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment()\n",
    "\n",
    "td3bc.fit(\n",
    "    dataset=d3_dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\"env\": EnvironmentEvaluator(env)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd244e62-d8d4-4aab-a17e-8aaf1bd128a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment(render_mode=\"human\", camera_id=2)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = td3bc.predict(obs[None])[0]\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(f\"Reward totale: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d325a-62f1-4758-9392-8b120b239ab4",
   "metadata": {},
   "source": [
    "# BCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8030e65-1e37-4ef6-b3a8-88626e899248",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcq = BCQConfig().create(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53fd42-83eb-48a6-ae3c-09b090ccba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcq.build_with_dataset(d3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3e768-82d2-4c47-b3f3-8c90dc582a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = dataset.recover_environment()\n",
    "\n",
    "bcq.fit(\n",
    "    dataset=d3_dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\"env\": EnvironmentEvaluator(env)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4ba29-c75f-4799-981d-93edacbe66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dataset.recover_environment(render_mode=\"human\", camera_id=2)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = bcq.predict(obs[None])[0]\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(f\"Reward totale: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8cb99a-a458-412c-921c-52b918f3dfb4",
   "metadata": {},
   "source": [
    "# AWAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a7e0a1-96a1-4b61-abff-7adcd743c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "awac = AWACConfig().create(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a41ca93-e3de-4ce1-b69a-db1c040e152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "awac.build_with_dataset(d3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93edcc22-2acf-4ae6-8e58-461d4f517199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:48.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float64')], shape=[(45,)]), action_signature=Signature(dtype=[dtype('float32')], shape=[(24,)]), reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)]), action_space=<ActionSpace.CONTINUOUS: 1>, action_size=24)\u001b[0m\n",
      "\u001b[2m2025-04-29 11:48.25\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-04-29 11:48.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/AWAC_20250429114825\u001b[0m\n",
      "\u001b[2m2025-04-29 11:48.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [45], 'action_size': 24, 'config': {'type': 'awac', 'params': {'batch_size': 1024, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'actor_optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'critic_optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'tau': 0.005, 'lam': 1.0, 'n_action_samples': 1, 'n_critics': 2}}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41628f2fb9846828ac31b10f9a19528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:48.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0064957036972045894, 'time_algorithm_update': 0.010676538467407227, 'critic_loss': 554.7457459411621, 'actor_loss': 425110.322421875, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.017215315580368044, 'env': 562.5663216534314}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:48.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_1000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46573ce964e144ff8660401c246886c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:49.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006325634002685547, 'time_algorithm_update': 0.010734166860580444, 'critic_loss': 546.8411540832519, 'actor_loss': 207324.41248828126, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.017101824045181273, 'env': 540.1014425113003}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:49.00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_2000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c630be6eef0f4eb2969380e93f473275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:49.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006434033870697022, 'time_algorithm_update': 0.010788160800933838, 'critic_loss': 1128.686857849121, 'actor_loss': 115807.14467773438, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.017263113498687744, 'env': 85.39976027247272}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:49.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_3000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096a49949a25464bbc5844d4851846f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:49.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006201712608337402, 'time_algorithm_update': 0.010133864879608155, 'critic_loss': 2037.0081600952149, 'actor_loss': 75400.00033557128, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.016375247716903688, 'env': 1626.3771405587713}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:49.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_4000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a24f7a77964b0f8dd507fa81f8d971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:49.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006261154413223267, 'time_algorithm_update': 0.010505888223648072, 'critic_loss': 3351.3476982421876, 'actor_loss': 51374.26865582275, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.01680708694458008, 'env': 552.7175959139385}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:49.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_5000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b88dcd276a94bed95cd232273b97a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:50.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=6 step=6000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00640866470336914, 'time_algorithm_update': 0.0100319242477417, 'critic_loss': 5012.912577270507, 'actor_loss': 36368.00639971924, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.016481981754302977, 'env': 623.78805076086}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m6000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:50.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_6000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cc11655d1041aaa7141c7d73820473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:50.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=7 step=7000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m7\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006795634508132934, 'time_algorithm_update': 0.011142736196517945, 'critic_loss': 7242.70580847168, 'actor_loss': 24817.51032544708, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.017982701301574706, 'env': 1404.1743881699217}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m7000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:50.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_7000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f66427268f24a159a3e6ee034e50db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:50.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=8 step=8000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m8\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006568410873413086, 'time_algorithm_update': 0.01032735800743103, 'critic_loss': 9595.429397705078, 'actor_loss': 19035.566874320983, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.016937438011169433, 'env': 463.13818769172406}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m8000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:50.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_8000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bd26f115bd4193b984b28e46fe1cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:51.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=9 step=9000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m9\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006766695022583008, 'time_algorithm_update': 0.011246136665344238, 'critic_loss': 12170.222025878906, 'actor_loss': 13423.196507347107, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.018054604053497316, 'env': 1530.4305660160392}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m9000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:51.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_9000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85010a296a564dd683962cce3886b48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-29 11:51.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAWAC_20250429114825: epoch=10 step=10000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m10\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006686381101608276, 'time_algorithm_update': 0.010797379970550537, 'critic_loss': 15307.128662597655, 'actor_loss': 9125.657841182709, 'temp': 0.0, 'temp_loss': 0.0, 'time_step': 0.017527610540390013, 'env': 1781.371999825909}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m10000\u001b[0m\n",
      "\u001b[2m2025-04-29 11:51.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/AWAC_20250429114825/model_10000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.0064957036972045894,\n",
       "   'time_algorithm_update': 0.010676538467407227,\n",
       "   'critic_loss': 554.7457459411621,\n",
       "   'actor_loss': 425110.322421875,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.017215315580368044,\n",
       "   'env': 562.5663216534314}),\n",
       " (2,\n",
       "  {'time_sample_batch': 0.006325634002685547,\n",
       "   'time_algorithm_update': 0.010734166860580444,\n",
       "   'critic_loss': 546.8411540832519,\n",
       "   'actor_loss': 207324.41248828126,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.017101824045181273,\n",
       "   'env': 540.1014425113003}),\n",
       " (3,\n",
       "  {'time_sample_batch': 0.006434033870697022,\n",
       "   'time_algorithm_update': 0.010788160800933838,\n",
       "   'critic_loss': 1128.686857849121,\n",
       "   'actor_loss': 115807.14467773438,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.017263113498687744,\n",
       "   'env': 85.39976027247272}),\n",
       " (4,\n",
       "  {'time_sample_batch': 0.006201712608337402,\n",
       "   'time_algorithm_update': 0.010133864879608155,\n",
       "   'critic_loss': 2037.0081600952149,\n",
       "   'actor_loss': 75400.00033557128,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.016375247716903688,\n",
       "   'env': 1626.3771405587713}),\n",
       " (5,\n",
       "  {'time_sample_batch': 0.006261154413223267,\n",
       "   'time_algorithm_update': 0.010505888223648072,\n",
       "   'critic_loss': 3351.3476982421876,\n",
       "   'actor_loss': 51374.26865582275,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.01680708694458008,\n",
       "   'env': 552.7175959139385}),\n",
       " (6,\n",
       "  {'time_sample_batch': 0.00640866470336914,\n",
       "   'time_algorithm_update': 0.0100319242477417,\n",
       "   'critic_loss': 5012.912577270507,\n",
       "   'actor_loss': 36368.00639971924,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.016481981754302977,\n",
       "   'env': 623.78805076086}),\n",
       " (7,\n",
       "  {'time_sample_batch': 0.006795634508132934,\n",
       "   'time_algorithm_update': 0.011142736196517945,\n",
       "   'critic_loss': 7242.70580847168,\n",
       "   'actor_loss': 24817.51032544708,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.017982701301574706,\n",
       "   'env': 1404.1743881699217}),\n",
       " (8,\n",
       "  {'time_sample_batch': 0.006568410873413086,\n",
       "   'time_algorithm_update': 0.01032735800743103,\n",
       "   'critic_loss': 9595.429397705078,\n",
       "   'actor_loss': 19035.566874320983,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.016937438011169433,\n",
       "   'env': 463.13818769172406}),\n",
       " (9,\n",
       "  {'time_sample_batch': 0.006766695022583008,\n",
       "   'time_algorithm_update': 0.011246136665344238,\n",
       "   'critic_loss': 12170.222025878906,\n",
       "   'actor_loss': 13423.196507347107,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.018054604053497316,\n",
       "   'env': 1530.4305660160392}),\n",
       " (10,\n",
       "  {'time_sample_batch': 0.006686381101608276,\n",
       "   'time_algorithm_update': 0.010797379970550537,\n",
       "   'critic_loss': 15307.128662597655,\n",
       "   'actor_loss': 9125.657841182709,\n",
       "   'temp': 0.0,\n",
       "   'temp_loss': 0.0,\n",
       "   'time_step': 0.017527610540390013,\n",
       "   'env': 1781.371999825909})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = dataset.recover_environment()\n",
    "\n",
    "awac.fit(\n",
    "    dataset=d3_dataset,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    evaluators={\"env\": EnvironmentEvaluator(env)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a1d3b2-c3ed-4829-a212-7efa399dfcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward totale: 3628.426871523513\n"
     ]
    }
   ],
   "source": [
    "env = dataset.recover_environment(render_mode=\"human\", camera_id=2)\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = awac.predict(obs[None])[0]\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "print(f\"Reward totale: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis-env)",
   "language": "python",
   "name": "thesis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
